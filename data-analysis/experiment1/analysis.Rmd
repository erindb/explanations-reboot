---
title: "Explanations Ratings"
author: "Erin"
output: 
html_document:
toc: false
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(
  echo=F, warning=F, #cache=T, 
  message=F, #sanitiz =T, 
  fig.width = 5, fig.height = 3)
```

```{r load_settings}
source("~/Settings/startup.R")
```

```{r load_data}
all_data = read.csv('../../data/experiment1-production-anonymized-results.csv') %>%
  mutate(explanation = char(explanation),
         workerid = factor(workerid))
demographics = all_data %>% group_by(workerid) %>%
  summarise(language=language[1],
            enjoyment=enjoyment[1],
            gender=gender[1],
            age=age[1],
            education=education[1],
            comments=comments[1],
            assess=assess[1],
            time_in_minutes=time_in_minutes[1]) %>%
  as.data.frame %>%
  mutate(language = char(language),
         enjoyment = factor(
           enjoyment,
           levels=c(-1, 0, 1, 2),
           labels=c("no response", "bad", "average", "good")),
         education = factor(
           education,
           levels=c(-1, 0, 1, 2, 3, 4),
           labels=c("no response",
                    "some high school",
                    "graduated high school",
                    "some college",
                    "graduated college",
                    "hold a higher degree"))
  )
parseExpl = function(explanationVector, variable) {
  newVector = sapply(explanationVector, function(expl) {
    words = strsplit(expl, " ")[[1]]
    elements = list()
    elements["explanandumVariable"] = words[1]
    elements["explanandumValue"] = words[3]=="present"
    becauseIndex = which(words=="because")
    elements["explanansVariable"] = words[becauseIndex+1]
    elements["explanansValue"] = words[becauseIndex+3]=="present"
    return(elements[[variable]])
  })
  return(unname(newVector))
}
df = all_data %>%
  # not a language experiment per se. I think... (?)
  # filter(language %in% c("English", "english", "ENGLIGH",
  #                        "eng", "ENG", "Eng")) %>%
  mutate(explanansVariable = factor(parseExpl(explanation,
                                       "explanansVariable")),
         explanansValue = parseExpl(explanation, 
                                    "explanansValue"),
         explanandumVariable = factor(parseExpl(explanation,
                                         "explanandumVariable")),
         explanandumValue = parseExpl(explanation,
                                      "explanandumValue")) %>%
  select(workerid, story, explanansVariable, explanansValue,
         explanandumVariable, explanandumValue, response) %>%
  mutate(story = factor(
    story,
    levels=c("story1", "story2", "story3b",
             "story4", "story5", "story6"),
    labels=c("story1", "story2", "story3",
             "story4", "story5", "story6"))) %>%
  mutate(
    utterance = paste(
    ifelse(explanandumValue, "", "! "),
    explanandumVariable,
    " because ",
    ifelse(explanansValue, "", "! "),
    explanansVariable,
    sep=""))
aggr_df = df %>%
  group_by(story, explanandumVariable,
           explanansVariable, utterance) %>%
  summarise(
    low = ci.low(response),
    high = ci.high(response),
    mean_response = mean(response)) %>%
  as.data.frame()
```

```{r save_data}
# write.csv(
#   df,
#   "../../data/full-explanations-elicitation-parsed-data.csv",
#   row.names=F)
# write.csv(
#   aggr_df,
#   "../../data/full-explananations-elicitation-aggregate-data.csv",
#   row.names=F)
```

```{r save_and_load_design}
# df %>% filter(workerid==1) %>%
#   select(story, explanansVariable, explanansValue,
#          explanandumVariable, explanandumValue) %>%
#   mutate(
#     utterance = paste(
#       ifelse(explanandumValue, "", "! "),
#       explanandumVariable,
#       " because ",
#       ifelse(explanansValue, "", "! "),
#       explanansVariable,
#       sep="")) %>%
# write.csv("../../data/full-explananations-elicitation-design.csv", row.names = F)
design = read.csv("../../data/full-explananations-elicitation-design.csv")
```

## Comparing explanations that overlap with initial ratings experiment

We ran a version where the explanans was fixed for each story and we ignored other explanations. Let's look at the subset of the new data that overlaps with that old data and see how they compare. Did the participants in this experiment give different responses on the overlapping explanations?

```{r replication_plot}
explanansVariableLookup = c("A", "B", "A", "C", "C", "B")
old_df = read.csv("../../data/2015-exp4-and-exp5-lkrep.csv") %>%
  filter(version == "explanation") %>%
  mutate(story = paste("story", story_index, sep=""),
         explanandumVariable = variable,
         explanansVariable = explanansVariableLookup[story_index]) %>%
  group_by(story, explanandumVariable, explanansVariable) %>%
  summarise(lk_only = mean(rating),
            ci.low = ci.low(rating),
            ci.high = ci.high(rating)) %>% as.data.frame
tags = read.csv("../../data/explanations-expt-data-with-fixed-explanans.csv") %>% select(story, story.number, variable, premise.variable, tag) %>%
  mutate(story = paste("story", story.number, sep="")) %>%
  rename(explanansVariable = premise.variable,
         explanandumVariable = variable)
compare_subset = aggr_df %>% 
  rename(full_version = mean_response) %>%
  merge(., merge(tags, old_df))
compare_subset %>% select(story, explanandumVariable, explanansVariable,
                          utterance, tag, story.number) %>%
  write.csv(., "../../data/lk-explanations-design.csv", row.names=F)
compare_subset %>%
  ggplot(., aes(x=lk_only, y=full_version,
                shape=explanandumVariable,
                colour=story)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point() +
  geom_errorbar(aes(x=lk_only, ymin=low, ymax=high)) +
  geom_errorbarh(aes(y=full_version, xmin=ci.low, xmax=ci.high)) +
  ylim(0,1) + xlim(0,1) +
  scale_colour_brewer(type="qual", palette=2) +
  ggtitle("replication of overlapping subset")
ggsave("replicated-subset.png", width=7, height=4)

compare_subset %>%
  ggplot(., aes(x=lk_only, y=full_version,
                colour=tag)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point() +
  geom_errorbar(aes(x=lk_only, ymin=low, ymax=high)) +
  geom_errorbarh(aes(y=full_version, xmin=ci.low, xmax=ci.high)) +
  ylim(0,1) + xlim(0,1) +
  scale_colour_brewer(type="qual", palette=2) +
  ggtitle("replication with tags")
ggsave("replicated-subset-with-tags.png", width=7, height=4)
```

Apparently, we replicated our previous experiment pretty well. r=`r with(compare_subset, cor(lk_only, full_version))`

## Ratings Results Overview

```{r observe_data}
plot_data_for_story = function(storylabel) {
  aggr_df %>% filter(story==storylabel) %>%
    ggplot(.,
           aes(x=explanansVariable,
               y=mean_response,
               group=explanandumVariable)) +
    geom_point() +
    geom_errorbar(
      aes(x=explanansVariable,
          ymin=low, ymax=high,
          group=explanandumVariable),
      width = 0) +
    geom_line() +
    xlab("Explanans") +
    ylab("rating") +
    ylim(0, 1) +
    facet_grid(~explanandumVariable)
}
```

```{r, fig.width=3, fig.height=2}
plot_data_for_story("story1")
knitr::include_graphics("lkstories-graphs/story1.png")
```

```{r, fig.width=3, fig.height=2}
plot_data_for_story("story2")
knitr::include_graphics("lkstories-graphs/story2.png")
```

```{r, fig.width=3, fig.height=2}
plot_data_for_story("story3")
knitr::include_graphics("lkstories-graphs/story3.png")
```

```{r, fig.width=3, fig.height=2}
plot_data_for_story("story4")
knitr::include_graphics("lkstories-graphs/story4.png")
```

```{r, fig.width=3, fig.height=2}
plot_data_for_story("story5")
knitr::include_graphics("lkstories-graphs/story5.png")
```

```{r, fig.width=3, fig.height=2}
plot_data_for_story("story6")
knitr::include_graphics("lkstories-graphs/story6.png")
```

## Model

```{r run_models}
# setwd("models")
# source("run_models.R")
# setwd("..")
```

Here's the model I presented in lab meeting plotted against the new data.

```{r}
model = read.csv("models/model_results/rsa_onelink_s2_explanansdependent_noentailments_uevenmore.csv") %>%
  rename(model = rating)
data = aggr_df
modelvdata = merge(model, data)
modelvdata %>% ggplot(., aes(x=model, y=mean_response,
                             colour=explanandumVariable,
                             shape=explanansVariable)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point() +
  geom_errorbar(aes(x=model, ymin=low, ymax=high)) +
  facet_wrap(~story)
```

But when I implemented this model for lab meeting, I actually made a few mistakes in creating the alternative causal structure for each utterance.

Here's what I currently consider a good algorithm for generating onelink causal uncertainty:

* if variables are not causally connected:
	* introduce causal link (p=0.5) before them in the direction indicated by the explanation.
	* new link is deterministic.
* if variables are directly causally connected:
	* reduce causal link probability to p=0.5.
	* when no cause, downstream variable deterministically takes its actual value
* if variables are indirectly causally connected:
	* reduce each causal link connecting them to p=0.5.
	* when no cause, downstream variable deterministically takes its actual value

Things I noticed were wrong with previous choice of causal uncertainty:

* The state of a variable whose parents have been disconnected from it should be its actual state. That wasn't the case in story 2 or 3.
* In story 3, C is an `xor` function of its two parents. I think I should have treated this as a single causal link rather than as 2 seperate ones. It makes the choice of what state C in the absense of its causal parent(s) much easier.

Using the above algorithm for generating causal uncertainty for each utterance, this is what the subset of the data that overlaps with the counterfactuals experiment look like for non-tautological explanations:

```{r}
improved_subset_model = read.csv("models/model_results/rsa-onelink-lksubset-improveduncertainty.csv") %>%
  rename(model = rating)
improved_subset_modelvdata = merge(improved_subset_model, data)
improved_subset_modelvdata %>% ggplot(., aes(x=model, y=mean_response,
                             colour=story,
                             shape=explanandumVariable)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point() +
  geom_errorbar(aes(x=model, ymin=low, ymax=high)) +
  ylim(0,1) + xlim(0,1)
improved_subset_model_cor = with(improved_subset_modelvdata, cor(model, mean_response))
orig_subset_model_cor = with(modelvdata %>% filter(explanansVariable!=explanandumVariable), cor(model, mean_response))
```

Making that improvement actually raises the model correlation with the LK subset of the data *without tautologies* from `r orig_subset_model_cor` to `r improved_subset_model_cor`.

And here's the model fit against all the data with the correct causal uncertainty for each utterance.

```{r}

```


## Participants

### Demographics

```{r observe_demographics, fig.width=2.5, fig.height=1.5}
demographics %>% ggplot(., aes(x=age)) +
  geom_histogram(binwidth = 1) +xlab("Age")
demographics %>%
  ggplot(., aes(x=time_in_minutes)) +
  geom_histogram(binwidth = 1) +
  xlab("Time in Minutes")
demographics %>% ggplot(., aes(x=assess)) +
  geom_bar() +xlab("Followed directions?")
demographics %>% ggplot(., aes(x=enjoyment)) +
  geom_bar() +xlab("Enjoyment")
demographics %>% ggplot(., aes(x=language)) +
  geom_bar() +xlab("Language")
```

### Comments

```{r observe_comments}
print(demographics$comments)
print(mean(demographics$time_in_minutes))
```

## References
