/*

Automated error analysis.

data: x1, x2, x3 -> y
We have a bunch of data points (x1, x2, y).
x1, x2 \in [0, 1].
y \in {0, 1}.
With these, we train a logistic regression.
We will simulate these data points from
	x1, x2 ~ uniform
	y ~ logistic(x1)
That is, y does not depend on x2 actually,
but it does depend on x1.

inference: learn b1, b2
Choose the MAP parameters for logistic regression.
We choose from:
	y ~ logistic(x1)
	y ~ logistic(x2)
	y ~ logistic(x1, x2)
	y ~ logistic(x2, x3)
	y ~ logistic(x1, x3)
	y ~ logistic(x1, x2, x3)

explain: misclassifications
Which term('s absense) was "responsible" for the error?

explanations: terms in the 
The agent can use the presense of absense of terms
in the regression as explanations of the misclassifications.

*/

// simulate data (R?)
// write data (R?)
// read data
// 

// webppl logistic.wppl --require utilities

// constants
var DATA = utilities.readCSV("logistic-data.csv", {types: ['num','num','bool','str'], header: true}).data;
var TRAIN = filter(function(d) {d.set=='train'}, DATA);
var TEST = filter(function(d) {d.set=='test'}, DATA);
var NTRAIN = TRAIN.length;
var NTEST = TEST.length;

var probability = function(dist, value) {return Math.exp(dist.score(value));};
var discreteUniform = Infer({method: 'rejection', samples: 1000}, function() {
  return uniform(0, 1);
});
var sampleWithUniformRV = function(args) {
	var prob = args.probability;
	var randomness = args.randomness;
	return randomness <= prob;
};

var independentLatentsModel = function() {
	var isTermInRegressionPrior = flip;
	var dataRandomnessPairs = map(function(i) {
		return ['r'+i, sample(discreteUniform)];
	}, utilities.range(0, NTEST));
	var allRandomness = dataRandomnessPairs.concat([
		['b1', isTermInRegressionPrior()],
		['b2', isTermInRegressionPrior()]
	]);
	return _.object(allRandomness);
};

var observablesModel = function(independentLatents) {

	var sigmoid = function(t) {
		return 1 / (1 + Math.exp(-t));
	};
	var predict = function(args) {
		var y = function(d, modelParams) {
			if (modelParams.structure == 'b1') {
				return modelParams.intercept + modelParams.b1*d.x1;
			} else if (modelParams.structure == 'b2') {
				return modelParams.intercept + modelParams.b2*d.x2;
			} else if (modelParams.structure == 'b1+b2') {
				return modelParams.intercept + modelParams.b1*d.x1 + modelParams.b2*d.x2;
			} else if (modelParams.structure == 'interceptOnly') {
				return modelParams.intercept;
			}
			display('ERROR 14325: NOT IMPLEMENTED');
		};
		var d = args.d;
		var modelParams = args.modelParams;
		return sigmoid(y(d, modelParams));
	};

	var includeB1 = independentLatents.b1;
	var includeB2 = independentLatents.b2;

	var trainedRegression = utilities.fitLogisticRegression(includeB1, includeB2, TRAIN);

	var observedPairs = map(function(i) {
		// predict, using randomness in independentLatents.
		var probTrue = predict({
			d: TEST[i],
			modelParams: trainedRegression
		});
		var randomness = independentLatents['r'+i];
		var classification = sampleWithUniformRV({
			probability: probTrue,
			randomness: randomness
		});
		return ['y'+i, classification];
	}, utilities.range(0, NTEST));

	var allObservables = observedPairs.concat([
		['structure', trainedRegression.structure],
		['includeB1', includeB1],
		['includeB2', includeB2]
	]);

	// return classificatins
	// and whether or not each dimension was a term in regression
	return _.object(allObservables);
};

var latents = independentLatentsModel();
var observables = observablesModel(latents);
display(observables);

// display(utilities.fitLogisticRegression(false, false, TRAIN));

"finished"