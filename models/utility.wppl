// Robot explains its behavior in a situation.

// environment: x1, x2

// utility: c1, c2

// inference: softmax with utility: c1*x1 + c2*x2

// explain: choice between:
// 	A (1,0)
// 	B (1,1)
// 	C (0,1)
// Why A?

// to do: set seed for debugging purposes

// some utilities
var infer = function(fn) {return Infer({method: 'enumerate'}, fn); };
var probability = function(dist, value) {return Math.exp(dist.score(value));};
var sampleWithUniformRV = function(dist, uniformRV) {
	var support = dist.support();
	var check = function(elems, probabilityMassSoFar) {
		var elemToCheck = first(elems);
		if (elems.length==1) {return elemToCheck;}
		var probabilityMass = probabilityMassSoFar + probability(dist, elemToCheck);
		if (uniformRV < probabilityMass) {
			return elemToCheck;
		} else {
			var elemsRemaining = rest(elems);
			return check(elemsRemaining, probabilityMass);
		}
	};
	check(support, 0);
};
var score = function(dist, value) {
	if (dist.support().indexOf(value) == -1) {
		// the actual value would "definitely" not happen
		return -Infinity;
	} else {
		return dist.score(value);
	}
};

// very rational agent
var lambda = 100;

/////////////////// utility program specification ///////////////////

// state choices
var states = {
	A: {x1: 1, x2: 0},
	B: {x1: 1, x2: 1},
	C: {x1: 0, x2: 1}
};

// priors on coefficients in utility function
var coefPrior = function() {
	// care or don't care about a dimension
	return uniformDraw([0, 1]);
};

// explanations: c1, c2, c1 OR c2, c1 AND c2
var discreteUniform = infer(function() {
	return uniformDraw([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]);
});

// utility function just weighs the dimensions of the state by the coefficients
var utility = function(state, coefficents) {
	return coefficents.c1 * state.x1 +
		coefficents.c2 * state.x2;
};

var determineAction = function(args) {
	// get action from posterior given an independent randomness variable "actionRandomness"
	var coefs = args.coefs;
	var actionRandomness = args.actionRandomness;

	// produces a posterior on actions based on the utilities of its possible actions
	var actionPosterior = infer(function() {
		// sample a state at uniform - no prior costs to options
		var stateLabel = uniformDraw(['A', 'B', 'C']);
		var state = states[stateLabel];

		// weight states by utility
		// calculate utilities of states based on your coefficients.
		factor(lambda * utility(state, coefs));

		return stateLabel;
	});

	var action = sampleWithUniformRV(actionPosterior, actionRandomness);

	return action;
};

var independentLatentsModel = function() {
	// to do: eventually insert checks that these are independent
	// these variables are either explanations, with their priors so we can counterfactualize
	// or unkown, unobservable sources of randomness
	return {
		actionRandomness: sample(discreteUniform),
		c1: coefPrior(),
		c2: coefPrior()
	}
};
var observablesModel = function(independentLatents) {
	var actionRandomness = independentLatents.actionRandomness;
	var c1 = independentLatents.c1;
	var c2 = independentLatents.c2;
	var coefs = {c1: c1, c2: c2};
	var action = determineAction({coefs: coefs, actionRandomness: actionRandomness});
	return {
		c1: c1,
		c2: c2,
		action: action
	}
};

/////////////////// counterfactualization ///////////////////

var counterfactualizeLatents = function(model, actual) {
	var s = 0.53; //stickiness
	var totallyDifferent = model();

	return mapObject(function(key, value) {
		return flip(s) ? actual[key] : totallyDifferent[key];
	}, actual);
}

var counterfactually = function(args) {
	var actualObservations = args.actualObservations;
	var ifTheseThingsHadBeenTrue = args.ifTheseThingsHadBeenTrue ? args.ifTheseThingsHadBeenTrue : null;
	var ifThisFunctionHadBeenTrue = args.ifThisFunctionHadBeenTrue ? args.ifThisFunctionHadBeenTrue : null;
	var thenThisVariable = args.thenThisVariable;
	var wouldHaveBeen = args.wouldHaveBeen ? args.wouldHaveBeen : null;
	var wouldNotHaveBeen = args.wouldNotHaveBeen ? args.wouldNotHaveBeen : null;

	return infer(function() {

		// generate an actual world (with latent random states)
		// conditioned on actual observables
		var actualLatents = independentLatentsModel();
		var actualObservables = observablesModel(actualLatents);
		// for each observation, confirm it has that value
		mapObject(function(key, value) {
			condition(actualObservables[key]==value);
		}, actualObservations);

		// generate a conterfactual world
		// hooked to the generated actual world
		var cfLatents = counterfactualizeLatents(independentLatentsModel, actualLatents);
		var cfObservables = observablesModel(cfLatents);

		// conditioned on the counterfactual premise
		if (ifTheseThingsHadBeenTrue) {
			mapObject(function(key, value) {
				condition(cfObservables[key]==value);
			}, ifTheseThingsHadBeenTrue);
		} else {
			condition(ifThisFunctionHadBeenTrue(cfObservables));
		}

		// return the counterfactual query
		if (wouldHaveBeen) {
			return cfObservables[thenThisVariable]==wouldHaveBeen;
		} else if (wouldNotHaveBeen) {
			return cfObservables[thenThisVariable]!=wouldNotHaveBeen;
		} else {
			// just return the full posterior of the query's values
			return cfObservables[thenThisVariable];
		}
	});
};

var actualObservations = {c1: 1, c2: 0, action: 'A'};

display("if the agent had cared about x2, it would have chosen B (1,1)")
display(probability(counterfactually({
	ifTheseThingsHadBeenTrue: {c2: 1},
	actualObservations: actualObservations,
	thenThisVariable: 'action',
	wouldHaveBeen: 'B'
}), true));

display("if the agent had not cared about x1, it might have chosen B (1,1)")
display(probability(counterfactually({
	ifTheseThingsHadBeenTrue: {c1: 0},
	actualObservations: actualObservations,
	thenThisVariable: 'action',
	wouldHaveBeen: 'B'
}), true));

/////////////////// explanation ///////////////////

var falsifyExplanation = function(explanation, actualObservations) {
	if (explanation == 'c1' | explanation == 'c2') {
		return function(cfObservables) {
			return cfObservables[explanation] != actualObservations[explanation];
		}
	} else if (explanation == 'c1 and c2 independently') {
		return function(cfObservables) {
			return (cfObservables.c1 != actualObservations.c1 &
				cfObservables.c2 != actualObservations.c2)==1;
		}
	} else if (explanation == 'c1 and c2 jointly') {
		return function(cfObservables) {
			return (cfObservables.c1 != actualObservations.c1 |
				cfObservables.c2 != actualObservations.c2) == 1;
		}
	}
};

var why = function(args) {
	var variableToExplain = args.variableToExplain;
	var causeIThoughtItWouldBe = args.causeIThoughtItWouldBe ? args.causeIThoughtItWouldBe : null;
	var possibleExplanations = args.possibleExplanations;
	var actualObservations = args.actualObservations;

	return infer(function() {
		var explanation = uniformDraw(possibleExplanations);

		// counterfactually if not explanation,
		// then "variableToExplain" would be different
		// (and might have been "causeIThoughtItWouldBe")
		var ifExplanationWereFalse = falsifyExplanation(explanation, actualObservations);
		var ifNotExplanationCounterfactual = counterfactually({
			ifThisFunctionHadBeenTrue: ifExplanationWereFalse,
			actualObservations: actualObservations,
			thenThisVariable: variableToExplain,
			wouldHaveBeen: causeIThoughtItWouldBe ? causeIThoughtItWouldBe : null,
			wouldNotHaveBeen: actualObservations[variableToExplain]
		});
		factor(score(ifNotExplanationCounterfactual, true));

		return "because " + explanation + "=" + actualObservations[explanation];
	});
}

display("Why A?");
// why A?
// because if not ___ then not A.
display(why({
	variableToExplain: 'action',
	possibleExplanations: ['c1', 'c2'],
	actualObservations: {action: 'A', c1: 1, c2: 0}
}));

display("Why A (and not B)?")
// why A and not B?
display(why({
	variableToExplain: 'action',
	causeIThoughtItWouldBe: 'B',
	possibleExplanations: ['c1', 'c2'],
	actualObservations: {action: 'A', c1: 1, c2: 0}
}));

display("Why A (and not C)?")
// why A and not C?
display(why({
	variableToExplain: 'action',
	causeIThoughtItWouldBe: 'C',
	possibleExplanations: ['c1', 'c2'],
	actualObservations: {action: 'A', c1: 1, c2: 0}
}));

'finished';
