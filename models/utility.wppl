/*

Robot explains its behavior in a situation.

environment: x1, x2
Suppose there are two dimensions of interest: X1 and X2.
They are continuous, x1 \in [0, 1] and x2 \in [0, 1].
These are dimensions of the environment that *could* be terms in a utility function.

utility: c1, c2
We construct an arbitrary utility function
with terms for each dimension.
The values of the coefficents c1, c2 \in {-1, 0, 1}
If X1 is good, then c1=1.
If X1 is bad, then c1=-1.
If it doesn't matter, c1=0.

inference: choose between two x1,x2 pairs
The agent can choose between two x1,x2 pairs.
Depending on the terms in the utility function,
it might make different choices,
given the same alternatives.

explain: choice
The agent must explain its choice of one x1,x2 pair over another.
For the sake of explanations, we can use a uniform prior over {-1, 0, 1}.

explanations: terms in the utility function
The agent can use either of its c1, c2 values as its explanation, or both.

*/

var states = [
	{x1: 0, x2: 0},
	{x1: 0, x2: 0.5},
	{x1: 0, x2: 1},
	{x1: 0.5, x2: 0},
	{x1: 0.5, x2: 0.5},
	{x1: 0.5, x2: 1},
	{x1: 1, x2: 0},
	{x1: 1, x2: 0.5},
	{x1: 1, x2: 1}
];

var utility = function(state, coefficents) {
	return coefficents.c1 * state.x1 +
		coefficents.c2 * state.x2;
};

var coefPrior = function() {
	return uniformDraw([0, 1]);
};

var choose = function(consequences, coefficents) {
	return Infer({method: 'enumerate'}, function() {
		var action = uniformDraw(['action', 'inaction']);
		if (action=='action') {
			factor(utility(consequences, coefficents));
		} // inaction has no consequences in this world
		return action;
	});
};

// var actualCoefs = {c1: 1, c2: 1};

// var posterior = choose({x1: 0, x2: 1}, actualCoefs);

// var action = sample(posterior);
// display(posterior);
// display(action);

// why was this action chosen?
// counterfactualize over utility terms
// possible answers:
//		because c1=1
//		because c2=1

// for each actual pair of coefficients
// graph a heat map of which is more likely to be
// referenced in the explanation *of its most probable action*
// i feel weird about explaining the unlikely action...
// I feel like the answer should be "well P(action)=blahblah" even though...

var discreteUniform = Infer(
	{method: 'rejection', samples:100},
	function(){return uniform(0,1);}
);
var prob = function(dist, val) {
	return Math.exp(dist.score(val));
};

var explanationsPrior = function() {
	return uniformDraw([ ['c1'], ['c2'], ['c1', 'c2'] ]);
};

var counterfactuallyifnot = function(explanation, params) {
	var actualCoefs = params.actualCoefs;
	var actualAction = params.actualAction;
	var consequences = params.consequences;
	var s = params.stickiness;

	Infer({method: 'enumerate'}, function() {
		// these inferences are actually unnecessary...
		// but in theory, there could be latent variables, too
		// so I'm keeping them around
		var coefs = {
			c1: coefPrior(),
			c2: coefPrior()
		};
		condition(coefs.c1==actualCoefs.c1);
		condition(coefs.c2==actualCoefs.c2);

		var actionThreshold = sample(discreteUniform);
		var actionPosterior = choose(consequences, coefs);
		var actionProbability = prob(actionPosterior, 'action');
		var action = (actionProbability >= actionThreshold ? 'action' : 'inaciton');
		condition(action==actualAction);

		var cfCoefs = {
			c1: flip(s) ? coefs.c1 : coefPrior(),
			c2: flip(s) ? coefs.c2 : coefPrior()
		};
		var cfActionThreshold = (flip(s) ? actionThreshold : sample(discreteUniform));
		var cfAction = (actionProbability >= cfActionThreshold ? 'action' : 'inaciton');

		// counterfactually, if not explanation...
		// i.e. if that variable(s) did not have that value...
		var explanationCoefs = map(function(ci) { return actualCoefs[ci] != cfCoefs[ci]; }, explanation);
		var notTheSame = sum(explanationCoefs)>=1;
		condition(notTheSame);

		// then actual action would be unlikely
		return cfAction==actualAction;
	});
};

var explain = function(params) {
	var actualCoefs = params.actualCoefs;
	var actualAction = params.actualAction;
	var consequences = params.consequences;
	var s = params.stickiness;

	return Infer({method: 'enumerate'}, function() {

		var explanation = explanationsPrior();

		var then = counterfactuallyifnot(explanation, params);
		// then actual action would be unlikely
		factor(prob(then, false));

		return explanation;
	})
};

explain({
	actualCoefs: {c1: 0, c2: 1},
	actualAction: 'action',
	consequences: {x1: 1, x2: 1},
	stickiness: 0.53
});

// var coefs = {
// 	c1: coefPrior(),
// 	c2: coefPrior()
// };
// var actionThreshold = sample(discreteUniform);
// var actionPosterior = choose({x1: 0, x2: 1}, coefs);
// var actionProbability = prob(actionPosterior, 'action');
// var action = (actionProbability >= actionThreshold ? 'action' : 'inaciton');
// display(actionPosterior);
// display(actionProbability);
// display(actionThreshold);
// action
