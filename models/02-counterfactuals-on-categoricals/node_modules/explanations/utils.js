// from MH: https://github.com/mhtess/generics/blob/master/models/node_modules/asymutils/asymutils.js

var fs = require('fs');
var babyparse = require('babyparse');
var ml = require('machine_learning');
var eps = 0.000001;

var fitLogisticRegression = function(includeB1, includeB2, data) {
  var x = [];
  var y = [];
  for (var i=0; i<data.length; i++) {
    var d = data[i];
    var x_vec = [];
    if (includeB1) { x_vec.push(d.x1); }
    if (includeB2) { x_vec.push(d.x2); }
    x.push(x_vec);
    y.push( d.label ? [1, 0] : [0, 1] );
  }
  var b2Index = null;
  var b1Index = null;
  var n_in = null;
  if (includeB1 & includeB2) {
    var structure = 'b1+b2';
    b1Index = 0;
    b2Index = 1;
    n_in = 2;
  } else if (includeB1 & !includeB2) {
    var structure = 'b1';
    b1Index = 0;
    n_in = 1;
  } else if (!includeB1 & includeB2) {
    var structure = 'b2';
    b2Index = 0;
    n_in = 1;
  } else {
    // structure is intercept only
    var structure = 'interceptOnly';
    x = x.map(function(lst) {return [1];});
    n_in = 1;
    // console.log("Warning 345: intercept implementation may be incorrect.")
  }
  var classifier = new ml.LogisticRegression({
    'input' : x,
    'label' : y,
    'n_in' : n_in,
    'n_out' : 2
  });
  classifier.set('log level',0);
  classifier.train({ lr: 0.1, epochs: 2000 });
  // console.log("Entropy : "+classifier.getReconstructionCrossEntropy());
  var b1 = (b1Index != null) ? (classifier.W[b1Index][0] - classifier.W[b1Index][1]) : 0;
  var b2 = (b2Index != null) ? (classifier.W[b2Index][0] - classifier.W[b2Index][1]) : 0;
  var intercept = (
    (structure=='interceptOnly') ? 
    classifier.W[0][0]-classifier.W[0][1]+classifier.b[0] - classifier.b[1] : 
    classifier.b[0] - classifier.b[1]);
  return {structure: structure, intercept: intercept, b1: b1, b2: b2};
};

var erpWriter = function(erp, filename) {
 var supp = erp.support([]);
 var csvFile = fs.openSync(filename, 'w');
 fs.writeSync(csvFile,'Parameter,Item,Prevalence,Value,Probability\n')
 supp.forEach(function(s) {supportWriter(s, Math.exp(erp.score([], s)), csvFile);})
 fs.closeSync(csvFile);
}

var inverseCDFMaxOverlap = function(erp, probability, origERP) {
  // is value more or less probable in CF world?
  var origsupp = origERP.support([]);
  var supp = erp.support([]);
  var cummulativeProbability = 0;
  var origSampler = {};
  for (var i=0; i<origsupp.length; i++) {
    var s = origsupp[i];
    var p = Math.exp(origERP.score(s));
    var start = cummulativeProbability;
    cummulativeProbability += p;
    origSampler[s] = {
      start: start,
      end: cummulativeProbability,
      p: p
    };
  }
  var newSampler = [];
  var openSpace = [];
  var leftoverProbMass = [];
  for (var i=0; i<supp.length; i++) {
    var s = supp[i];
    var p = Math.exp(erp.score(s));
    var start = origSampler[s].start;
    var origP = origSampler[s].p;
    var origEnd = origSampler[s].end;
    var end;
    if (origP == p) {
      end = origEnd;
    } else if (origP < p) {
      end = origEnd;
      leftoverProbMass.push({ s: s, p: p - origP });
    } else {
      end = start + p;
      openSpace.push({ start: end, end: end + (origP - p) });
    }
    newSampler.push(
      {s: s, start: start, end: end}
    );
  }
  // first double check that leftover prob mass == open space
  var totalLeftoverProbMass = 0;
  for (var i=0; i<leftoverProbMass.length; i++) {
    totalLeftoverProbMass += leftoverProbMass[i].p;
  }
  var totalOpenSpace = 0;
  for (var i=0; i<openSpace.length; i++) {
    totalOpenSpace += (openSpace[i].end - openSpace[i].start);
  }
  if (totalOpenSpace-totalLeftoverProbMass > eps) {
    console.log("error 2301 in utils.js sampling function");
  }
  // for each open space gap,
  for (var i=0; i<openSpace.length; i++) {
    // fill in a scaled version of leftover mass
    var openSpaceToFill = openSpace[i];
    var fillable = openSpaceToFill.end - openSpaceToFill.start;
    var scaleFactor = fillable / totalLeftoverProbMass;
    var startFillingInHere = openSpaceToFill.start;
    for (var j=0; j<leftoverProbMass.length; j++) {
      var leftoverMassToAdd = leftoverProbMass[j];
      var s = leftoverMassToAdd.s;
      var p = leftoverMassToAdd.p;
      var scaledP = p*scaleFactor;
      var start = startFillingInHere;
      var end = start + scaledP;
      startFillingInHere += scaledP;
      newSampler.push({
        s: s,
        start: start,
        end: end
      });
    }
  }
  for (var i=0; i<newSampler.length; i++) {
    var start = newSampler[i].start;
    var end = newSampler[i].end;
    var s = newSampler[i].s;
    if (start <= probability & probability <= end) {
      return s;
    }
  }
  // then fill in all open space with all probability mass
  return s;
}

var inverseCDF = function(erp, probability) {
  var supp = erp.support([]);
  var cummulativeProbability = 0;
  for (var i=0; i<supp.length; i++) {
    var s = supp[i];
    cummulativeProbability += Math.exp(erp.score(s));
    if (probability<=cummulativeProbability) {
      return s;
    }
  }
  return s;
}

var supportWriter = function(s, p, handle) {
 var sLst = _.pairs(s);
 var l = sLst.length;

 for (var i = 0; i < l; i++) {
   fs.writeSync(handle, sLst[i].join(',')+','+p+'\n');
 }
}

function retype(value, type) {
  if (type=='num') {
    return parseFloat(value);
  } else if (type=='bool') {
    return ['True', 'T', 'TRUE', 'true', '#t', '1', 1].indexOf(value) >= 0;
  }
  return value;
}

function readCSV(filename, args){
  var output = babyparse.parse(fs.readFileSync(filename, 'utf8'));
  if (output.data[output.data.length-1].length==1) {
    output.data = output.data.slice(0, output.data.length-1);
  }
  if (args.header) {
    output.columns = {};
    var keys = output.data[0];
    for (var i=0; i<keys.length; i++) {
      output.columns[keys[i]] = [];
    }
    output.data = output.data.slice(1);
    output.data = output.data.map(function(values) {
      var newObject = {};
      for (var i=0; i<values.length; i++) {
        if (args.types) {
          newValue = retype(values[i], args.types[i]);
        } else {
          newValue = values[i];
        }
        newObject[keys[i]] = newValue;
        output.columns[keys[i]].push(newValue);
      }
      return newObject;
    })
  }
  return output;
};

function writeCSV(jsonCSV, filename){
  fs.writeFileSync(filename, babyparse.unparse(jsonCSV) + "\n");
};

function wpParseFloat(x){
  return parseFloat(x);
};

function range(a, b, increment) {
  var increment = increment ? increment : 1;
  var numbers = [];
  if (a<=b) {
    for (var i=a; i<b; i+=increment) {
      numbers.push(i);
    }
  } else {
    for (var i=a; i>b; i-=increment) {
      numbers.push(i);
    }
  }
  return numbers;
};

module.exports = {
  readCSV: readCSV,
  writeCSV: writeCSV,
  wpParseFloat: wpParseFloat,
  erpWriter:erpWriter,
  range: range,
  fitLogisticRegression: fitLogisticRegression,
  inverseCDF: inverseCDF,
  inverseCDFMaxOverlap: inverseCDFMaxOverlap
};