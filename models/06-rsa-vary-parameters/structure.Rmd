---
title: "All booleans! Vary structure!"
author: "Erin Bennett"
output: 
html_document:
toc: false
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=F, warning=F, cache=T, message=F, sanitiz =T, fig.width = 5, fig.height = 3)
```

```{r load_settings}
# install.packages('devtools')
# devtools::install_github("mhtess/rwebppl")
source("~/Settings/startup.R")
library(reshape2)
```

## 1. Using only boolean variables, do counterfactual probabilities match up with L&K's model?

```{r}
counterfactual = function(model, variable, storynumber,
                          premise.variable, premise.value) {
  program_file = paste(model, "/lk", storynumber,
                       "/autoexpanded.wppl", sep="")
  rs = webppl(program_file = program_file,
              inference_opts = list(method="enumerate"),
              model_var = paste(
                "function() {return counterfactual(0.53, {'",
                premise.variable,
                "': ",
                ifelse(premise.value, "true", "false"),
                "});}",
                sep=""),
              packages = "./node_modules/jsUtils")
  return(sum(rs[rs[[variable]]==T, "prob"]))
}
```

```{r}
lk.model = read.csv("lk-model-data-numbers.csv") %>%
  mutate(my.model = mapply(counterfactual, "rsa.base.booleans", variable,
                           story, premise.variable, premise.value),
         story = factor(story))

lk.model %>% ggplot(., aes(x=rating, y=my.model, colour=story)) +
  geom_point()
```

Yep.

## 2. What about explanations?

We have human ratings for some explanations. In each story from L&K, we have two explanations that share an explanans (e.g. "B because A" and "C because A").

```{r, fig.height=5}
expl = read.csv("explanations-expt-data.csv")
ggplot(expl, aes(x=variable, y=rating)) +
  geom_point() + geom_errorbar(aes(ymin=ci.low, ymax=ci.high), width=0) +
  facet_wrap(~story, scale="free") +
  ylim(0, 1)
```

This display is a bit difficult to interpret, because each story corresponds to its own causal structure and each is also associated with a specific configuration of what is true of the "actual world". So later in this writeup, I'll go story-by-story and explanation-by-explanation to try to understand the data and compare them to the predicitons of various models.

Let's first take a simple model of explanations as speech acts, and compare it to the data that we have.

### First Pass Model

So, there are different ways to do a model of explanation, and the whole point of this exercise is to ultimately come up with a really good one.

For now, let's say that all utterances are equally probable. (We could later add in a cost for the length of an utterance, but let's leave that for much later.)

At first, let's try having a *bunch* of alternative utterances, including "and" statements and simple statements of a single variable's value. (We might want to narrow this down to only explanations. We might want to narrow this down even further to explanations whose component expressions are true in the world.)



