/*

Automated error analysis.

data: x1, x2, x3 -> y
We have a bunch of data points (x1, x2, y).
x1, x2 \in [0, 1].
y \in {0, 1}.
With these, we train a logistic regression.
We will simulate these data points from
	x1, x2 ~ uniform
	y ~ logistic(x1)
That is, y does not depend on x2 actually,
but it does depend on x1.

inference: learn b1, b2
Choose the MAP parameters for logistic regression.
We choose from:
	y ~ logistic(x1)
	y ~ logistic(x2)
	y ~ logistic(x1, x2)
	y ~ logistic(x2, x3)
	y ~ logistic(x1, x3)
	y ~ logistic(x1, x2, x3)

explain: misclassifications
Which term('s absense) was "responsible" for the error?

explanations: terms in the 
The agent can use the presense of absense of terms
in the regression as explanations of the misclassifications.

*/

// simulate data (R?)
// write data (R?)
// read data
// 

// webppl logistic.wppl --require utilities

// constants
var DATA = utilities.readCSV("logistic-data.csv", {types: ['num','num','bool','str'], header: true}).data;
var TRAIN = filter(function(d) {d.set=='train'}, DATA);
var TEST = filter(function(d) {d.set=='test'}, DATA);
var NTRAIN = TRAIN.length;
var NTEST = TEST.length;

// some utilities
var infer = function(fn) {return Infer({method: 'enumerate'}, fn); };
var score = function(dist, value) {
	if (dist.support().indexOf(value) == -1) {
		// the actual value would "definitely" not happen
		return -Infinity;
	} else {
		return dist.score(value);
	}
};
// very rational agent
var lambda = 100;
var probability = function(dist, value) {return Math.exp(dist.score(value));};
var discreteUniform = Infer({method: 'rejection', samples: 1000}, function() {
  return uniform(0, 1);
});
var sampleWithUniformRV = function(args) {
	var prob = args.probability;
	var randomness = args.randomness;
	return randomness <= prob;
};

var independentLatentsModel = function() {
	var isTermInRegressionPrior = flip;
	var dataRandomnessPairs = map(function(i) {
		return ['r'+i, sample(discreteUniform)];
	}, utilities.range(0, NTEST));
	var allRandomness = dataRandomnessPairs.concat([
		['b1', isTermInRegressionPrior()],
		['b2', isTermInRegressionPrior()]
	]);
	return _.object(allRandomness);
};

var observablesModel = cache(function(independentLatents) {

	var sigmoid = function(t) {
		return 1 / (1 + Math.exp(-t));
	};
	var predict = function(args) {
		var y = function(d, modelParams) {
			if (modelParams.structure == 'b1') {
				return modelParams.intercept + modelParams.b1*d.x1;
			} else if (modelParams.structure == 'b2') {
				return modelParams.intercept + modelParams.b2*d.x2;
			} else if (modelParams.structure == 'b1+b2') {
				return modelParams.intercept + modelParams.b1*d.x1 + modelParams.b2*d.x2;
			} else if (modelParams.structure == 'interceptOnly') {
				return modelParams.intercept;
			}
			display('ERROR 14325: NOT IMPLEMENTED');
		};
		var d = args.d;
		var modelParams = args.modelParams;
		return sigmoid(y(d, modelParams));
	};

	var includeB1 = independentLatents.b1;
	var includeB2 = independentLatents.b2;

	var trainedRegression = utilities.fitLogisticRegression(includeB1, includeB2, TRAIN);

	var observedPairs = map(function(i) {
		// predict, using randomness in independentLatents.
		var probTrue = predict({
			d: TEST[i],
			modelParams: trainedRegression
		});
		var randomness = independentLatents['r'+i];
		var classification = sampleWithUniformRV({
			probability: probTrue,
			randomness: randomness
		});
		return ['y'+i, classification];
	}, utilities.range(0, NTEST));

	var allObservables = observedPairs.concat([
		['structure', trainedRegression.structure],
		['includeB1', includeB1],
		['includeB2', includeB2]
	]);

	// return classificatins
	// and whether or not each dimension was a term in regression
	return _.object(allObservables);
});

var latents = independentLatentsModel();
var observables = observablesModel(latents);
display(observables);

// display(utilities.fitLogisticRegression(false, false, TRAIN));

/////////////////// counterfactualization ///////////////////

var counterfactualizeLatents = function(model, actual) {
	var s = 0.53; //stickiness
	var totallyDifferent = model();

	return mapObject(function(key, value) {
		return flip(s) ? actual[key] : totallyDifferent[key];
	}, actual);
}

var counterfactually = function(args) {
	var actualObservations = args.actualObservations;
	var ifTheseThingsHadBeenTrue = args.ifTheseThingsHadBeenTrue ? args.ifTheseThingsHadBeenTrue : null;
	var ifThisFunctionHadBeenTrue = args.ifThisFunctionHadBeenTrue ? args.ifThisFunctionHadBeenTrue : null;
	var thenThisVariable = args.thenThisVariable;
	var wouldHaveBeen = args.wouldHaveBeen ? args.wouldHaveBeen : null;
	var wouldNotHaveBeen = args.wouldNotHaveBeen ? args.wouldNotHaveBeen : null;

	return infer(function() {

		// generate an actual world (with latent random states)
		// conditioned on actual observables
		var actualLatents = independentLatentsModel();
		var actualObservables = observablesModel(actualLatents);
		// for each observation, confirm it has that value
		mapObject(function(key, value) {
			condition(actualObservables[key]==value);
		}, actualObservations);

		// generate a conterfactual world
		// hooked to the generated actual world
		var cfLatents = counterfactualizeLatents(independentLatentsModel, actualLatents);
		var cfObservables = observablesModel(cfLatents);

		// conditioned on the counterfactual premise
		if (ifTheseThingsHadBeenTrue) {
			mapObject(function(key, value) {
				condition(cfObservables[key]==value);
			}, ifTheseThingsHadBeenTrue);
		} else {
			condition(ifThisFunctionHadBeenTrue(cfObservables));
		}

		// return the counterfactual query
		if (wouldHaveBeen) {
			return cfObservables[thenThisVariable]==wouldHaveBeen;
		} else if (wouldNotHaveBeen) {
			return cfObservables[thenThisVariable]!=wouldNotHaveBeen;
		} else {
			// just return the full posterior of the query's values
			return cfObservables[thenThisVariable];
		}
	});
};


// display("if the agent had cared about x2, it would have chosen B (1,1)")
// display(probability(counterfactually({
// 	ifTheseThingsHadBeenTrue: {c2: 1},
// 	actualObservations: actualObservations,
// 	thenThisVariable: 'action',
// 	wouldHaveBeen: 'B'
// }), true));

// display("if the agent had not cared about x1, it might have chosen B (1,1)")
// display(probability(counterfactually({
// 	ifTheseThingsHadBeenTrue: {c1: 0},
// 	actualObservations: actualObservations,
// 	thenThisVariable: 'action',
// 	wouldHaveBeen: 'B'
// }), true));

// ------------- explanation -------------

var falsifyExplanation = function(explanation, actualObservations) {
	if (explanation == 'b1' | explanation == 'b2') {
		return function(cfObservables) {
			return cfObservables[explanation] != actualObservations[explanation];
		}
	} else {
		console.log("error 492: not implemented")
	}
};

var why = function(args) {
	var variableToExplain = args.variableToExplain;
	var causeIThoughtItWouldBe = args.causeIThoughtItWouldBe ? args.causeIThoughtItWouldBe : null;
	var possibleExplanations = args.possibleExplanations;
	var actualObservations = args.actualObservations;

	return infer(function() {
		var explanation = uniformDraw(possibleExplanations);

		// counterfactually if not explanation,
		// then "variableToExplain" would be different
		// (and might have been "causeIThoughtItWouldBe")
		var ifExplanationWereFalse = falsifyExplanation(explanation, actualObservations);
		var ifNotExplanationCounterfactual = counterfactually({
			ifThisFunctionHadBeenTrue: ifExplanationWereFalse,
			actualObservations: actualObservations,
			thenThisVariable: variableToExplain,
			wouldHaveBeen: causeIThoughtItWouldBe ? causeIThoughtItWouldBe : null,
			wouldNotHaveBeen: actualObservations[variableToExplain]
		});
		factor(score(ifNotExplanationCounterfactual, true));

		return "because " + explanation + "=" + actualObservations[explanation];
	});
}

// ------------- error analysis -------------
var errorAnalysis = function(observations) {
	// pick out the errors
	// explain each of them.
	map(function(i) {
		var correct = observations['y'+i]==TEST[i].label;
		// if incorrect, explain why not correct.
		if (!correct) {
			display("why was y" + i + " incorrect?");
			display(why({
				variableToExplain: 'y' + i,
				possibleExplanations: ['b1', 'b2'],
				actualObservations: observations
			}))
		}
	}, utilities.range(0, NTEST));
};

var actualObservations = { y0: true,
  y1: false,
  y2: true,
  y3: true,
  y4: true,
  y5: true,
  y6: true,
  y7: true,
  y8: true,
  y9: false,
  structure: 'b2',
  includeB1: false,
  includeB2: true
};
errorAnalysis(actualObservations);

// display("Why B?")
// // why A and not C?
// display(why({
// 	variableToExplain: 'action',
// 	// possibleExplanations: ['c1', 'c2'],
// 	possibleExplanations: ['c1', 'c2', 'c1 and c2 jointly', 'c1 and c2 independently'],
// 	actualObservations: {action: 'B', c1: 1, c2: 1}
// }));

"finished"