In their original experiment in their counterfactual probability elicitation condition, Lucas & Kemp (2015) recruited 55 in-lab participants 56 online participants. From these participants, they excluded data from 25 in-lab and 22 online participants for giving responses inconsistent with the counterfactual premises (e.g. given a premise "A is absent" participants would be excluded if they gave a number other than 0 in response to "How likely is it that A would have been present?"), leaving 30 in-lab and 34 online participants whose data were analyzed. In our new version where we elicited ratings for explanations, we chose not to use such exclusion criteria, and we ran our experiment only online via Amazon's Mechanical Turk.

In our pilot experiment, we replicated Lucas & Kemp's counterfactuals experiment with 20 participants and modified the experiment to elicit explanation ratings rather than counterfactuals. Using the same variables as Lucas & Kemp, we recruited and analysed data from 20 participants for the explanations pilot. For the explanation ratings elicitation only (not the counterfactual probability elicitation), we then collected data for all possible explanations given the actual states of variables. This increased the length of the experiment such that participants in the new version spent an average of 19 minutes on the task, whereas participants in the pilot version spent an average of 7 minutes on the task. In the pilot version, participants were compensated $0.80. In the full version, participants were compensated $1.00. (This is probably not enough. Robert says he would compensate them $2.00 for that amount of time.)

We recruited a similar number of total participants, 90* online participants, and analyzed data from all of them. So our analyzed dataset was smaller than L&K's full dataset, but larger than their analyzed dataset.



* I originally thought 120, because I thought mturk batches were in groups of 10 (they're actually in groups of 9), and that the price was fair. Lots of turkers complained about the payment, and so I decided to stop earlier. I did look at some of the data before I made this decision, but I don't really have any hypotheses that are relevant to the data.