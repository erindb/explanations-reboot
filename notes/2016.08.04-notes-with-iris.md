* agent being *self*-aware is cool. as opposed to a seperate explaining agent.
* dialogue agents would be neat to explain. Stuff like maybe Stanley Peters is doing?
* it's interesting if an agent can coordinate and represent the *user's* beliefs and expectations while it's explaining
* explanations: beliefs, desires, evidence, confidence, rationality, obstacles, context, plans, cost
* a useful planning example:
	* I'm in a coffee shop. I want to buy a coffee. But I don't have money. I have to first walk outside to the ATM to get money, then go back to the coffee shop to buy a coffee.
	* "I thought you wanted a coffee. Why did you go outside?" someone might ask