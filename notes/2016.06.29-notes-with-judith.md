* Really the conjunctive explanation should be the best, right?
* Are there any corpus studies of why questions?
* Things that might be explanations:
	- current state
	- beliefs about current state / outcomes of actions
	- desired endstates
	- latent states (with diff utilities)
* In words:
	- b/c I was in this state.
	- b/c i wanted that state
	- b/c that state is good
* Are actions deterministic?
* What is the QUD???!!!
	- why did you do that? (as opposed to what you *should* have done)
* Give simplesimple model an options to explain with a conjunction of parameters in the utlity function. is that best?
* build in a simple QUD?
* what if an agent chooses an action that's less good in their posterior?
	- it can explain in terms of its rationality parameter alpha.
	- it could say "because i'm human" -> apocolypse scenario, this is what the robot responsible says. lol
* model the common ground
	- utility structure
	- space of actions
	- consequences of actions
	- lambda (rationality)
	- make a table of which knolwedge states are logically possible and what explanations they prompt
* collect why qns in the world. people seem to negotiate about what's in common ground.
